(window.webpackJsonp=window.webpackJsonp||[]).push([[37],{127:function(e,t,n){"use strict";n.d(t,"a",(function(){return m})),n.d(t,"b",(function(){return d}));var r=n(0),a=n.n(r);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function p(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=a.a.createContext({}),l=function(e){var t=a.a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):p(p({},t),e)),n},m=function(e){var t=l(e.components);return a.a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.a.createElement(a.a.Fragment,{},t)}},b=a.a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,i=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),m=l(n),b=r,d=m["".concat(i,".").concat(b)]||m[b]||u[b]||o;return n?a.a.createElement(d,p(p({ref:t},s),{},{components:n})):a.a.createElement(d,p({ref:t},s))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=b;var p={};for(var c in t)hasOwnProperty.call(t,c)&&(p[c]=t[c]);p.originalType=e,p.mdxType="string"==typeof e?e:r,i[1]=p;for(var s=2;s<o;s++)i[s]=n[s];return a.a.createElement.apply(null,i)}return a.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"},250:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-170923-15e15e092f85a322bb207f399dbb63e2.png"},251:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-171041-69354b04605af8ea2deea221f34ef1d1.png"},252:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-171133-5f37f0276ee0ff9e7be663fbdaa7b195.png"},253:function(e,t,n){"use strict";n.r(t),t.default=n.p+"assets/images/hyperparamtuning-173059-7bf96693d2d1f4f366b99907e0936819.png"},98:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return i})),n.d(t,"rightToc",(function(){return p})),n.d(t,"default",(function(){return s}));var r=n(2),a=(n(0),n(127));const o={title:"Hyperparameter tuning",sidebar_label:"Hyperparameter tuning",description:"Onepanel - Hyperparameter tuning"},i={unversionedId:"reference/workflows/hyperparameter-tuning",id:"reference/workflows/hyperparameter-tuning",isDocsHomePage:!1,title:"Hyperparameter tuning",description:"Onepanel - Hyperparameter tuning",source:"@site/docs/reference/workflows/hyperparameter-tuning.md",slug:"/reference/workflows/hyperparameter-tuning",permalink:"/docs/reference/workflows/hyperparameter-tuning",editUrl:"https://github.com/onepanelio/core-docs/tree/master/docs/reference/workflows/hyperparameter-tuning.md",version:"current",sidebar_label:"Hyperparameter tuning",sidebar:"reference",previous:{title:"Accessing TensorBoard",permalink:"/docs/reference/workflows/tensorboard"},next:{title:"Troubleshooting Workflows",permalink:"/docs/reference/workflows/troubleshooting"}},p=[{value:"Setting up your Workflow Template",id:"setting-up-your-workflow-template",children:[]},{value:"Understanding the configurations",id:"understanding-the-configurations",children:[]},{value:"Executing your Workflow",id:"executing-your-workflow",children:[]},{value:"Persisting best metrics, model and hyperparameters",id:"persisting-best-metrics-model-and-hyperparameters",children:[]}],c={rightToc:p};function s({components:e,...t}){return Object(a.b)("wrapper",Object(r.a)({},c,t,{components:e,mdxType:"MDXLayout"}),Object(a.b)("p",null,"Onepanel supports hyperparameter tuning for your TensorFlow and PyTorch models by fully integrating with ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/microsoft/nni"}),"NNI")," and its ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://nni.readthedocs.io/en/stable/Tuner/BuiltinTuner.html"}),"built-in tuners"),"."),Object(a.b)("p",null,"To understand how to add hyperparameter tuning into Onepanel Workflows, we'll walk through the starter template under ",Object(a.b)("strong",{parentName:"p"},"Workflows")," > ",Object(a.b)("strong",{parentName:"p"},"Workflow Templates")," > ",Object(a.b)("strong",{parentName:"p"},"Create Template")," > ",Object(a.b)("strong",{parentName:"p"},"Hyperparameter tuning"),"."),Object(a.b)("p",null,"There are 3 steps for integrating hyperparameter tuning into any training Workflow:"),Object(a.b)("ol",null,Object(a.b)("li",{parentName:"ol"},"Model training code - Make minor updates to grab hyperparameters from NNI and report accuracies back to NNI."),Object(a.b)("li",{parentName:"ol"},"Workflow Template - Minor changes to the ",Object(a.b)("strong",{parentName:"li"},"Hyperparameter tuning")," starter template to point to your code repository and paths."),Object(a.b)("li",{parentName:"ol"},"Configuration - This is a field in the Workflow Template and it is where you indicate the type of tuner (e.g. TPE), the search space for hyperparameters and their corresponding ranges, path to your model training code, whether to use GPUs, etc.")),Object(a.b)("h2",{id:"setting-up-your-workflow-template"},"Setting up your Workflow Template"),Object(a.b)("ol",null,Object(a.b)("li",{parentName:"ol"},Object(a.b)("p",{parentName:"li"},"First, make changes to your training code to grab the parameters from NNI and report results back to NNI. Highlighted below are all the changes we had to make to ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/onepanelio/templates/tree/v0.18.0/workflows/hyperparameter-tuning/mnist/main.py"}),"MNIST example code")," which is used in the ",Object(a.b)("strong",{parentName:"p"},"Hyperparameter tuning")," starter template to support hyperparameter tuning. The ",Object(a.b)("inlineCode",{parentName:"p"},"...")," indicate code that was removed for brevity."),Object(a.b)("pre",{parentName:"li"},Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-python",metastring:"{1,4-7,25,32,49-50}","{1,4-7,25,32,49-50}":!0}),"import nni\n\n# Callback class for reporting intermediate accuracy metrics.\nclass ReportIntermediates(Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        \"\"\"Reports intermediate accuracy to NNI framework\"\"\"\n        nni.report_intermediate_result(logs['val_accuracy'])\n\ndef main(args, params):\n    ...\n\n    model = tf.keras.Sequential([\n        ...\n    ])\n    model.compile(...)\n\n    ...\n\n    model.fit(\n        x_train,\n        y_train,\n        batch_size=params['batch_size'],\n        epochs=params['epochs'],\n        # Add callback class for intermediate accuracy reporting\n        callbacks=[ReportIntermediates(), tensorboard],\n        validation_data=(x_test, y_test)\n    )\n\n    ...\n    \n    # send final accuracy to NNI tuner and web UI\n    nni.report_final_result(accuracy)\n    \n    ...\n\nif __name__ == '__main__':\n    ...\n\n    params = {\n        'dropout_rate': 0.5,\n        'conv_size': 5,\n        'hidden_size': 1024,\n        'batch_size': 32,\n        'learning_rate': 1e-4,\n        'epochs': 10,\n    }\n\n    # fetch hyper-parameters from NNI tuner\n    tuned_params = nni.get_next_parameter()\n    params.update(tuned_params)\n\n    _logger.info('Hyperparameters: %s', params)\n    main(parser.parse_args(), params)\n"))),Object(a.b)("li",{parentName:"ol"},Object(a.b)("p",{parentName:"li"},"Go to ",Object(a.b)("strong",{parentName:"p"},"Workflows")," > ",Object(a.b)("strong",{parentName:"p"},"Workflow Templates")," > ",Object(a.b)("strong",{parentName:"p"},"Create Template")," and select ",Object(a.b)("strong",{parentName:"p"},"Hyperparameter tuning"),".")),Object(a.b)("li",{parentName:"ol"},Object(a.b)("p",{parentName:"li"},"Update the Workflow Template to use your repository and update the paths in ",Object(a.b)("inlineCode",{parentName:"p"},"/mnt/src")," to match your repository's directory structure. The ",Object(a.b)("inlineCode",{parentName:"p"},"...")," indicate sections that were removed for brevity."),Object(a.b)("pre",{parentName:"li"},Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml",metastring:"{7,11,33,46}","{7,11,33,46}":!0}),"entrypoint: main\narguments:\n    parameters:\n    # [CHANGE] Path to your training/model architecture code repository\n    # Change this value and revision value to your code repository and branch respectively\n    - name: source\n      value: https://github.com/onepanelio/templates\n    # [CHANGE] Revision is the branch or tag that you want to use\n    # You can change this to any tag or branch name in your repository\n    - name: revision\n      value: v0.18.0\n...\ntemplates:\n- name: main\n    dag:\n        tasks:\n        - name: hyperparameter-tuning\n          template: hyperparameter-tuning\n...\n- name: hyperparameter-tuning\n  inputs:\n    artifacts:\n    - name: src\n      # Clone the above repository into `/mnt/data/src` - see https://docs.onepanel.ai/docs/reference/workflows/artifacts#git for private repositories\n      git:\n        repo: '{{workflow.parameters.source}}'\n        revision: '{{workflow.parameters.revision}}'\n      path: /mnt/data/src\n    - name: config\n      # [CHANGE] Path where config.yaml will be generated or already exists\n      # Update the path below so that config.yaml is written to the same directory as your main.py file\n      # Note that your source code is cloned to /mnt/data/src\n      path: /mnt/data/src/<path-to-training-code-directory>/config.yaml\n      raw:\n        data: '{{workflow.parameters.config}}'\n...\n  container:\n    image: onepanel/dl:0.20.0\n    command:\n      - sh\n      - -c\n    args:\n      # [CHANGE] Update the path below to point to your code and config.yaml path as described above\n      # Note that you can \"pip install\" additional tools here if necessary\n      - |\n        cd /mnt/data/src/<path-to-training-code-directory>/ && \\\n        python -u /opt/onepanel/nni/start.py --config config.yaml\n...\n"))),Object(a.b)("li",{parentName:"ol"},Object(a.b)("p",{parentName:"li"},"Update the Workflow Template title and click ",Object(a.b)("strong",{parentName:"p"},"Save"),"."))),Object(a.b)("h2",{id:"understanding-the-configurations"},"Understanding the configurations"),Object(a.b)("p",null,"When executing your new hyperparameter tuning Workflow Template, you will most likely need to adjust the ",Object(a.b)("inlineCode",{parentName:"p"},"Configuration")," parameter to indicate the type of tuner (e.g. TPE), update the search space for hyperparameters and their corresponding ranges, set the path to your model training code and set the number of GPUs."),Object(a.b)("p",null,"Here is a description of each of the fields in the ",Object(a.b)("inlineCode",{parentName:"p"},"Configuration")," parameter:"),Object(a.b)("pre",null,Object(a.b)("code",Object(r.a)({parentName:"pre"},{className:"language-yaml"}),"experimentName: MNIST TF v2.x\nmaxExperimentDuration: 1h\nmaxTrialNumber: 10\ntrainingService:\n  platform: local\n  useActiveGpu: True\ntuner:\n  name: TPE                  # choices: TPE, Random, Anneal, Evolution, BatchTuner, MetisTuner, GPTuner\n  classArgs:\n    optimize_mode: maximize  # choices: maximize, minimize\ntrialConcurrency: 1\ntrialGpuNumber: 0            # update number to number of GPUs if GPU is present\ntrialCommand: python main.py --output /mnt/output\n# [CHANGE] Search space configuration\n# Change according to your hyperparameters and ranges\nsearchSpace:\n  dropout_rate:\n    _type: uniform\n    _value: [0.5,0.9]\n  conv_size:\n    _type: choice\n    _value: [2,3,5,7]\n  hidden_size:\n    _type: choice\n    _value: [124,512,1024]\n  batch_size:\n    _type: choice\n    _value: [16,32]\n  learning_rate:\n    _type: choice\n    _value: [0.0001,0.001,0.01,0.1]\n  epochs:\n    _type: choice\n    _value: [10]\n")),Object(a.b)("div",{className:"admonition admonition-important alert alert--info"},Object(a.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-heading"}),Object(a.b)("h5",{parentName:"div"},Object(a.b)("span",Object(r.a)({parentName:"h5"},{className:"admonition-icon"}),Object(a.b)("svg",Object(r.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(a.b)("path",Object(r.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"important")),Object(a.b)("div",Object(r.a)({parentName:"div"},{className:"admonition-content"}),Object(a.b)("p",{parentName:"div"},"See ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://nni.readthedocs.io/en/stable/reference/experiment_config.html"}),"NNI's Experiment Config Reference")," for more information and list of all available fields."))),Object(a.b)("h2",{id:"executing-your-workflow"},"Executing your Workflow"),Object(a.b)("p",null,"Now that you have set up your hyperparameter tuning Workflow Template and have a good understanding of the various configurations, you can execute the Workflow via Onepanel ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"/docs/reference/workflows/execute"}),"Web UI")," or ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/onepanelio/python-sdk/blob/master/examples/execute-workflow.ipynb"}),"Python SDK"),". "),Object(a.b)("p",null,"Once the Workflow is running, you can see your training progress in ",Object(a.b)("strong",{parentName:"p"},"TensorBoard")," and ",Object(a.b)("strong",{parentName:"p"},"NNI Web UI")," right from your Workflow Task by clicking on the ",Object(a.b)("strong",{parentName:"p"},"hyperparameter-tuning")," Task, then clicking ",Object(a.b)("strong",{parentName:"p"},"Outputs"),"."),Object(a.b)("p",null,Object(a.b)("img",{src:n(250).default})),Object(a.b)("p",null,"Clicking ",Object(a.b)("strong",{parentName:"p"},"Open NNI Web UI")," will display the following screen in a new tab:"),Object(a.b)("p",null,Object(a.b)("img",{src:n(251).default})),Object(a.b)("p",null,"You can also view the corresponding TensorBoard by clicking ",Object(a.b)("strong",{parentName:"p"},"Open TensorBoard"),":"),Object(a.b)("p",null,Object(a.b)("img",{src:n(252).default})),Object(a.b)("h2",{id:"persisting-best-metrics-model-and-hyperparameters"},"Persisting best metrics, model and hyperparameters"),Object(a.b)("p",null,"Although optional, you should persist the best metrics to your Workflow and save the best model and parameters to your object storage."),Object(a.b)("p",null,"Refer to the ",Object(a.b)("a",Object(r.a)({parentName:"p"},{href:"https://github.com/onepanelio/templates/tree/v0.18.0/workflows/hyperparameter-tuning/mnist/main.py"}),"MNIST example code")," for an example of how to do this."),Object(a.b)("p",null,Object(a.b)("img",{src:n(253).default})))}s.isMDXComponent=!0}}]);