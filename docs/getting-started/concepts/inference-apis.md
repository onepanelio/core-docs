---
title: Inference APIs
sidebar_label: Inference APIs
description: Onepanel Serverless Inference APIs allow you to deploy your PyTorch and TensorFlow models
---

You can deploy your TensorFlow and PyTorch models using Onepanel's Inference APIs. These APIs can scale to and from zero on CPUs and GPUs, and can be deployed using [Web UI](/docs/reference/inference-apis/create-with-web-ui), [Workflow Tasks](/docs/reference/inference-apis/create-with-workflow-task) and Onepanel's [Python SDk](/docs/reference/inference-apis/create-with-python-sdk).

:::important
Onepanel's Inference APIs are based on [KFServing](https://github.com/kubeflow/kfserving) and are fully compatible.
:::
